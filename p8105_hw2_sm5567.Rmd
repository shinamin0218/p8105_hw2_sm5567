---
title: "Homework 2"
author: "Shina Min"
date: '`r format(Sys.time(), "%Y-%m-%d")`'
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

### Problem 0

This solution focuses on a reproducible report containing code and text necessary for Problems 1-3, and is organized as an R Project. This was not prepared as a GitHub repo; examples for repository structure and git commits should be familiar from other elements of the course.

Throughout, we use appropriate text to describe our code and results, and use clear styling to ensure code is readable. 

```{r load_libraries}
library(tidyverse)
library(readxl)
```


### Problem 1

We clean the 538 `pols` data, which provides information on the number of national politicians who are democratic or republican at any given time. There are some values for which `prez_gop` is `2` -- these are months in which Ford became President following Nixon's resignation. In the new `president` variable created as part of our data cleaning, we code these as `gop` (same as values when `prez_gop` is `1`).

```{r clean_538_pols}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols =
  read_csv("./fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez"))
```

We also clean the 538 `snp` data, which contains information related to Standard & Poorâ€™s stock market index.

```{r clean_538_snp}
snp = 
  read_csv(
    "./fivethirtyeight_datasets/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

Finally, we tidy the `unemployment` data so that it can be merged with the `pols` and `snp` datasets.

```{r clean_538_unemp}
unemployment = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Now we merge the three datasets!

```{r merge_538}
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
```

Notice that there are some `NA` values in the `close` and `unemployment` variables, which indicate that the value of these variables is missing at those locations.

Let's talk about the 538 datasets. The `pols` data has `r nrow(pols)` observations and `r ncol(pols)` variables and tells us about the party affiliation distribution (democrat or republican) for governors and senators for a given year from years `r pols |> pull(year) |> min()` to `r pols |> pull(year) |> max()`. It also tells us whether the sitting president was a democrat or republican. The `snp` data has `r nrow(snp)` observations and `r ncol(snp)` variables, ranging from years `r snp |> pull(year) |> min()` to `r snp |> pull(year) |> max()`. The `unemployment` data has `r nrow(unemployment)` observations and `r ncol(unemployment)` variables ranging from years `r unemployment |> pull(year) |> min()` to `r unemployment |> pull(year) |> max()`. In Januarys in or after 1975 in which a democrat was president, the **average unemployment rate was `r filter(data_538, month == "January", year >= 1975, president == "dem") |> pull(unemployment) |> mean() |> round(2)`**.  The average unemployment rate over the same time period in which a republican was president was `r filter(data_538, month == "January", year >= 1975, president == "gop") |> pull(unemployment) |> mean() |> round(2)`.


### Problem 2

This problem uses the Mr. Trash Wheel dataset, available as an Excel file on the course website.

Read and clean the Mr. Trash Wheel sheet:

```{r}
library(tidyverse)
library(readxl)
library(dplyr)
```

## Reading and cleaning Trash Wheel Collection Data

```{r}
mr_trash_wheel =
  read_excel("./202309 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel",
             range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(homes_powered = (weight_tons * 500) / 30,
         trash_wheel_data = 1,
         year = as.numeric(year))

prof_trash_wheel =
  read_excel("./202309 Trash Wheel Collection Data.xlsx",
             sheet = "Professor Trash Wheel",
             range = cell_cols("A:M")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(homes_powered = (weight_tons * 500) / 30,
         trash_wheel_data = 2)

gwy_trash_wheel =
  read_excel("./202309 Trash Wheel Collection Data.xlsx",
             sheet = "Gwynnda Trash Wheel",
             range = cell_cols("A:J")) %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>%
  mutate(homes_powered = (weight_tons * 500) / 30,
         trash_wheel_data = 3)
```

## Merging three data sets

```{r}
trash_wheel_data =
 bind_rows(mr_trash_wheel, prof_trash_wheel, gwy_trash_wheel) %>%
  janitor::clean_names()
trash_wheel_data
```

In the `mr_trash_wheel` dataset, there are 15 variables, and 584 observations. The average number of homes powered is 53.3 and the total weight of trash collected is 1875 tons.

The `prof_trash_wheel` dataset includes 14 variables and 106 observations. The average number of homes powered is 34. The total weight of trash collected is 216 tons.

Lastly, the `gwy_trash_wheel` dataset has 12 variables and 155 observations. The average number of homes powered is 48.6 and the total weight of trash collected is 452 tons. The total number of cigarette butts collected by Gwynnda in July of 2021 is 16300.


### Problem 3

## Importing, cleaning and tidying the dataset + mutating status + removing participants do not meet the criteria.
Import, clean, and tidy the dataset of baseline demographics. Ensure that sex and APOE4 carrier status are appropriate encoded (i.e. not numeric), and remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline).
```{r}
mci_df =
  read_csv("data_mci/MCI_baseline.csv", skip = 1, na = ".") %>% ## reading mci_df in csv
  janitor::clean_names() %>% ## cleaning the names, using the janitor function
  mutate(sex = recode(sex, `0` = "male", `1` = "female")) %>%
  mutate(apoe4 = recode(apoe4, "1" = "carrier", "0" = "non-carrier")) %>%
  filter(age_at_onset != ".", age_at_onset > current_age)
## selecting some variables and then mutating and then getting rid of the missing values.

female_apoe4 =
  filter(mci_df, sex == "female")
nrow(female_apoe4) ## The proportion of women who are APOE4 carriers using nrow function
```

* To import, clean and tidy the dataset of baseline demographics, I started giving the data set a name. I defined the baseline data as `mci_df`.
* Then, I read mci_df in csv, using `read_csv` function I learned in lectures.
* Next, I cleaned the names by using `janitor::clean_names()` function.
* Since sex data is in numeric values (male = 0, female =1), I changed the values to male and female by using `mutate()` function as I learned in class.
* I also changed APOE4 carieer status from numeric values to carrier and non-carrier. In order to change the APOE4 status, I also used `mutate()` function and `recode()` function.
* Lastly, to eliminate any participants who do not meet the stated inclusion criteria (with no MCI at baseline), I used `filter()` function by putting `!` sign in front of the `.` data (no MCI at baseline) and kept all other columns by specifying the condition using `age_at_onset > current_age`.


Discuss important steps in the import process and relevant features of the dataset. How many participants were recruited, and of these how many develop MCI? What is the average baseline age? What proportion of women in the study are APOE4 carriers? (ASK)
```{r}
mean(mci_df$current_age) ## the mean age of baseline age
```
* Number of participants were reurited is 479 (from the datasets), ___ people develop MCI 
* The mean age of baseline age is 65.542
* The proportion of women in the study that are also APOE4 carriers is 48.


comment on the steps on the import process and the features of the dataset. (NEED)
## Importing, cleaning and tidying the dataset of longitudinally observed biomarker values
```{r}
amyloid_df =
  read.csv("data_mci/mci_amyloid.csv", skip =1) %>% ## reading amyloid_df in read_csv
  janitor::clean_names() ## cleaning names, using janitor::clean_names function

colnames(amyloid_df)[colnames(amyloid_df) == "study_id"] = "id"
## Specifying what are the column names by using colnames function

amyloid_df

all_data =
  full_join(mci_df, amyloid_df, by = "id")
all_data ## Merging all the datasets by using full_join function
```

Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings.

* Participants appear in only the baseline datasets: antijoin_ (two steps to do it)
* Participants appear in only the amyloid datasets:


Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory. (ASK)

