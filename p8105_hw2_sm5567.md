Homework 2
================
Shina Min
2023-10-04

### Problem 0

This solution focuses on a reproducible report containing code and text
necessary for Problems 1-3, and is organized as an R Project. This was
not prepared as a GitHub repo; examples for repository structure and git
commits should be familiar from other elements of the course.

Throughout, we use appropriate text to describe our code and results,
and use clear styling to ensure code is readable.

``` r
library(tidyverse)
library(readxl)
```

### Problem 1

We clean the 538 `pols` data, which provides information on the number
of national politicians who are democratic or republican at any given
time. There are some values for which `prez_gop` is `2` – these are
months in which Ford became President following Nixon’s resignation. In
the new `president` variable created as part of our data cleaning, we
code these as `gop` (same as values when `prez_gop` is `1`).

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )

pols =
  read_csv("./fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) |> 
  select(year, month, everything(), -day, -starts_with("prez"))
```

We also clean the 538 `snp` data, which contains information related to
Standard & Poor’s stock market index.

``` r
snp = 
  read_csv(
    "./fivethirtyeight_datasets/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

Finally, we tidy the `unemployment` data so that it can be merged with
the `pols` and `snp` datasets.

``` r
unemployment = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

Now we merge the three datasets!

``` r
data_538 = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(data_538)
## tibble [822 × 13] (S3: tbl_df/tbl/data.frame)
##  $ year        : num [1:822] 1947 1947 1947 1947 1947 ...
##  $ month       : chr [1:822] "January" "February" "March" "April" ...
##  $ month_num   : int [1:822] 1 2 3 4 5 6 7 8 9 10 ...
##  $ gov_gop     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
##  $ sen_gop     : num [1:822] 51 51 51 51 51 51 51 51 51 51 ...
##  $ rep_gop     : num [1:822] 253 253 253 253 253 253 253 253 253 253 ...
##  $ gov_dem     : num [1:822] 23 23 23 23 23 23 23 23 23 23 ...
##  $ sen_dem     : num [1:822] 45 45 45 45 45 45 45 45 45 45 ...
##  $ rep_dem     : num [1:822] 198 198 198 198 198 198 198 198 198 198 ...
##  $ president   : chr [1:822] "dem" "dem" "dem" "dem" ...
##  $ month_abb   : chr [1:822] "Jan" "Feb" "Mar" "Apr" ...
##  $ close       : num [1:822] NA NA NA NA NA NA NA NA NA NA ...
##  $ unemployment: num [1:822] NA NA NA NA NA NA NA NA NA NA ...
```

Notice that there are some `NA` values in the `close` and `unemployment`
variables, which indicate that the value of these variables is missing
at those locations.

Let’s talk about the 538 datasets. The `pols` data has 822 observations
and 11 variables and tells us about the party affiliation distribution
(democrat or republican) for governors and senators for a given year
from years 1947 to 2015. It also tells us whether the sitting president
was a democrat or republican. The `snp` data has 787 observations and 3
variables, ranging from years 1950 to 2015. The `unemployment` data has
816 observations and 3 variables ranging from years 1948 to 2015. In
Januarys in or after 1975 in which a democrat was president, the
**average unemployment rate was 6.57**. The average unemployment rate
over the same time period in which a republican was president was 6.47.

### Problem 2

This problem uses the Mr. Trash Wheel dataset, available as an Excel
file on the course website.

Read and clean the Mr. Trash Wheel sheet:

``` r
library(tidyverse)
library(readxl)
library(dplyr)
```

## Reading and cleaning Trash Wheel Collection Data

``` r
mr_trash_wheel =
  read_excel("./202309 Trash Wheel Collection Data.xlsx",
             sheet = "Mr. Trash Wheel",
             range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(homes_powered = (weight_tons * 500) / 30,
         trash_wheel_data = 1,
         year = as.numeric(year))

prof_trash_wheel =
  read_excel("./202309 Trash Wheel Collection Data.xlsx",
             sheet = "Professor Trash Wheel",
             range = cell_cols("A:M")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(homes_powered = (weight_tons * 500) / 30,
         trash_wheel_data = 2)

gwy_trash_wheel =
  read_excel("./202309 Trash Wheel Collection Data.xlsx",
             sheet = "Gwynnda Trash Wheel",
             range = cell_cols("A:J")) %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>%
  mutate(homes_powered = (weight_tons * 500) / 30,
         trash_wheel_data = 3)
```

- To load the `mr_trash_wheel` dataset, I used the `read_excel` function
  and specified the sheet and range by using `sheet` and `range`
  functions. Then I cleaned the name using the `janitor::clean_names()`
  function. I dropped the dumpster data (unnecessary data that doesn’t
  incoude dumpster-specific data). I used calculation described in the
  Homes powered note and updated the data to include a new homes_powered
  variable based on this calculation by using the `mutate()` function,
  multiplying `weight_tons` by 500 and divded them with 30. Lastly, I
  converted the year variable to a numeric data tye by using the
  `as.numeric()`.
- I repeated the same step for the rest of `prof_trash_wheel` dataset
  and `gwy_trash_wheel` dataset.

## Merging three data sets

``` r
trash_wheel_data =
 bind_rows(mr_trash_wheel, prof_trash_wheel, gwy_trash_wheel) %>% ## merging datasets
  janitor::clean_names() ## cleaning the names, using the janitor function
trash_wheel_data ## loading the merged datasets
## # A tibble: 845 × 15
##    dumpster month  year date                weight_tons volume_cubic_yards
##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
## # ℹ 835 more rows
## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>,
## #   trash_wheel_data <dbl>
```

- In the `mr_trash_wheel` dataset, there are 15 variables, and 584
  observations. The average number of homes powered is 53.3 and the
  total weight of trash collected is 1875 tons.

- The `prof_trash_wheel` dataset includes 14 variables and 106
  observations. The average number of homes powered is 34. The total
  weight of trash collected is 216 tons.

- Lastly, the `gwy_trash_wheel` dataset has 12 variables and 155
  observations. The average number of homes powered is 48.6 and the
  total weight of trash collected is 452 tons. The total number of
  cigarette butts collected by Gwynnda in July of 2021 is 16300.

### Problem 3

## Importing, cleaning and tidying the dataset + mutating status + removing participants do not meet the criteria.

``` r
mci_df =
  read_csv("data_mci/MCI_baseline.csv", skip = 1, na = ".") %>% ## reading mci_df in csv
  janitor::clean_names() %>% ## cleaning the names, using the janitor function
  mutate(sex = recode(sex, `0` = "male", `1` = "female")) %>%
  mutate(apoe4 = recode(apoe4, "1" = "carrier", "0" = "non-carrier")) %>%
  filter(age_at_onset != ".", age_at_onset > current_age)
## selecting some variables and then mutating and then getting rid of the missing values.

female_apoe4 =
  filter(mci_df, sex == "female")
nrow(female_apoe4) ## the proportion of women who are APOE4 carriers using nrow function
## [1] 48
```

- To import, clean and tidy the dataset of baseline demographics, I
  started giving the data set a name. I defined the baseline data as
  `mci_df()`.
- I had to remove the first row of data due to it containing repeat
  information that is already found in the columns.
- Then, I read mci_df in csv, using `read_csv` function I learned in
  lectures.
- Next, I cleaned the names by using `janitor::clean_names()` function.
- Since sex data is in numeric values (male = 0, female =1), I changed
  the values to male and female by using `mutate()` and
  `recode()`function as I learned in class.
- I also changed APOE4 carieer status from numeric values to carrier and
  non-carrier. In order to change the APOE4 status, I also used
  `mutate()` function and `recode()` function.
- Lastly, to eliminate any participants who do not meet the stated
  inclusion criteria (with no MCI at baseline), I used `filter()`
  function by putting `!` sign in front of the `.` data (no MCI at
  baseline) and kept all other columns by specifying the condition using
  `age_at_onset > current_age`.

## Number of people developed MCI, the average baseline age and the proportion of APOE4 carrier women.

``` r
mean(mci_df$current_age) ## finding the mean age of baseline age
## [1] 65.54194

nrow(mci_df)
## [1] 93
ncol(mci_df)
## [1] 6
filter(mci_df, age_at_onset !=".") %>%
  nrow()
## [1] 93
```

- Number of participants were reurited is 479 (from the datasets), 93
  people develop MCI during the study. In the study contained 93,
  participants and had ’r ncol(mci_df)\` variables. of the 93
  participants recruited at baseline, 93 developed MCI during the study.
- The mean age of baseline age is 65.542. I used 65.5419355 function to
  find the mean age of baseline age.
- The proportion of women in the study that are also APOE4 carriers
  is 48. To find this proportion, I used and then 48 and got 48.

## Importing, cleaning, tidying and combining the dataset of longitudinally observed biomarker values.

    ## # A tibble: 90 × 11
    ##       id current_age sex    education apoe4  age_at_onset baseline time_2 time_4
    ##    <dbl>       <dbl> <chr>      <dbl> <chr>         <dbl> <chr>    <chr>  <chr> 
    ##  1     3        62.5 female        16 carri…         66.8 0.10608… 0.108… 0.106…
    ##  2     5        66   female        16 non-c…         68.7 0.10795… 0.112… 0.115…
    ##  3     7        66.5 female        18 non-c…         74   0.11224… <NA>   0.104…
    ##  4    13        63.1 female        12 carri…         69   0.11030… 0.108… 0.108…
    ##  5    18        67.8 female        16 non-c…         69.8 0.11413… 0.107… 0.110…
    ##  6    22        67.3 male          20 carri…         74.6 0.10932… <NA>   0.107…
    ##  7    26        64.8 male          20 carri…         71.1 0.10474… 0.110… 0.106…
    ##  8    30        66.3 male          12 non-c…         73.1 0.10931… 0.111… 0.107…
    ##  9    39        68.3 male          16 carri…         70.2 0.10442… <NA>   0.103…
    ## 10    43        67.1 male          16 carri…         71.6 0.11042… 0.105… <NA>  
    ## # ℹ 80 more rows
    ## # ℹ 2 more variables: time_6 <chr>, time_8 <chr>

- I had to remove the first row of data due to it containing repeat
  information that is already found in the columns.
- Then I read the `amyloid_df` in csv by using the `read.csv` function.
  Next, I cleaned the name by using the `janitor::clean_names()`
  function.
- To specify the column names, I used `colnames(amyloid_df)` and renamed
  `student_id` to “id” for consistency when merging.
- The dataset contains participant information during the study’s
  follow-up period.
- Key variables include `id` and `baseline`, as well as fixed time
  intervals labeled `time_2`, `time_4`, `time_6`, and `time_8`.
- Lastly, I merged all the datasets of `mci_df` and `amyloid_df` by
  using the `inner_join()` function.
- I printed out the dataset, putting the `all_data` function.
- I hid the long dataset of `all_data` by using `echo = FALSE` function
  next to the {r}.

## Participants appear in only the amyloid datasets:

All participants in `mci_df` (baseline) are in `amyloid_df`. However,
participants with study id’s from 472 to 495 are only in the
`amyloid_df`. Without specific information, I could assume that some
participants may only present in the `amyloid_df` and not the `mci_df`
(baseline) because of participants being added to the dataset after the
baseline data collection started.

## Exporting the result as a CSV to my data directory.
